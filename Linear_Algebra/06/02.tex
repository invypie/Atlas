\section{Characteristic Values}

The introductory remarks of the previous section provide us with a starting point for our attempt to analyze the general linear operator \(T\). We take our cue from \eqref{eq:6.2}, which suggests that we should study vectors which are sent by \(T\) into scalar multiples of themselves.

\begin{definition}
    Let \(V\) be a vector space over the field \(F\) and let \(T\) be a linear operator on \(V\). A \emph{characteristic value} of \(T\) is a scalar \(c\) in \(F\) such that there is a non-zero vector \(\alpha\) in \(V\) with \(T\alpha=c\alpha\). If \(c\) is a characteristic value of \(T\), then
    \begin{enumerate}
        \item any \(\alpha\) such that \(T\alpha=c\alpha\) is called a \emph{characteristic vector} of \(T\) associated with the characteristic value \(c\);
        \item the collection of all \(\alpha\) such that \(T\alpha=c\alpha\) is called the \emph{characteristic space} associated with \(c\).
    \end{enumerate}
\end{definition}

Characteristic values are often called characteristic roots, latent roots, eigenvalues, proper values, or spectral values. In this book we shall use only the name `characteristic values.'

If \(T\) is any linear operator and \(c\) is any scalar, the set of vectors \(\alpha\) such that \(T\alpha=c\alpha\) is a subspace of \(V\). It is the null space of the linear transformation \(\left(T-cI\right)\). We call \(c\) a characteristic value of \(T\) if this subspace is different from the zero subspace, i.e., if \(\left(T-cI\right)\) fails to be \(1\):\(1\). If the underlying space \(V\) is finite-dimensional, \(\left(T-cI\right)\) fails to be \(1\):\(1\) precisely when its determinant is different from \(0\). Let us summarize.

\begin{theorem}
    Let \(T\) be a linear operator on a finite-dimensional space \(V\) and let \(c\) he a scalar. The following are equivalent.
    \begin{enumerate}
        \item \(c\) is a characteristic value of \(T\).
        \item The operator \(\left(T-cI\right)\) is singular (not invertible).
        \item\label{itm:6.2.5} \(\det\left(T-cI\right)=0\).
    \end{enumerate}
\end{theorem}

The determinant criterion~\ref{itm:6.2.5} is very important because it tells us where to look for the characteristic values of \(T\). Since \(\det\left(T-cI\right)\) is a polynomial of degree \(n\) in the variable \(c\), we will find the characteristic values as the roots of that polynomial. Let us explain carefully.

If \(\symcal{B}\) is any ordered basis for \(V\) and \(A=\left[T\right]_{\symcal{B}}\), then \(\left(T-cI\right)\) is invertible if and only if the matrix \(\left(A-cI\right)\) is invertible. Accordingly, we make the following definition.

\begin{definition}
    If \(A\) is an \(n\times n\) matrix over the field \(F\), a \emph{characteristic value of \(A\) in \(F\)} is a scalar \(c\) in \(F\) such that the matrix \(\left(A-cI\right)\) is singular (not invertible).
\end{definition}

Since \(c\) is a characteristic value of \(A\) if and only if \(\det\left(A-cI\right)=0\), or equivalently if and only if \(\det\left(cI-A\right)=0\), we form the matrix \(\left(xI-A\right)\) with polynomial entries, and consider the polynomial \(f=\det\left(xI-A\right)\). Clearly the characteristic values of \(A\) in \(F\) are just the scalars \(c\) in \(F\) such that \(f\left(c\right)=0\). For this reason \(f\) is called the \emph{characteristic polynomial} of \(A\). It is important to note that \(f\) is a monic polynomial which has degree exactly \(n\). This is easily seen from the formula for the determinant of a matrix in terms of its entries.

\begin{lemma}
    Similar matrices have the same characteristic polynomial.
\end{lemma}

\begin{proof}
    It \(B=P^{-1}AP\), then
    \begin{align*}
        \det\left(xI-B\right)&=\det\left(xI-P^{-1}AP\right)\\
        &=\det\left(P^{-1}\left(xI-A\right)P\right)\\
        &=\det P^{-1}\cdot\det\left(xI-A\right)\cdot\det P\\
        &=\det\left(xI-A\right).\qedhere
    \end{align*}
\end{proof}

This lemma enables us to define sensibly the characteristic polynomial of the operator \(T\) as the characteristic polynomial of any \(n\times n\) matrix which represents \(T\) in some ordered basis for \(V\). Just as for matrices, the characteristic values of \(T\) will be the roots of the characteristic polynomial for \(T\). In particular, this shows us that \(T\) cannot have more than \(n\) distinct characteristic values. It is important to point out that \(T\) may not have any characteristic values.

\begin{example}\label{example:6.1}
    Let \(T\) be the linear operator on \(R^2\) which is represented in the standard ordered basis by the matrix
    \begin{equation*}
        A=
        \begin{bmatrix}
            0 & -1 \\
            1 & 0
        \end{bmatrix}
        .
    \end{equation*}
    The characteristic polynomial for \(T\) (or for \(A\)) is
    \begin{equation*}
        \det\left(xI-A\right)=
        \begin{vmatrix}
            x & 1 \\
            -1 & x
        \end{vmatrix}
        =x^2+1.
    \end{equation*}
    Since this polynomial has no real roots, \(T\) has no characteristic values. If \(U\) is the linear operator on \(C^2\) which is represented by \(A\) in the standard ordered basis, then \(U\) has two characteristic values, \(\iu\) and \(-\iu\). Here we see a subtle point. In discussing the characteristic values of a matrix \(A\), we must be careful to stipulate the field involved. The matrix \(A\) above has no characteristic values in \(R\), but has the two characteristic values \(\iu\) and \(-\iu\) in \(C\).
\end{example}

\begin{example}\label{example:6.2}
    Let \(A\) be the (real) \(3\times3\) matrix
    \begin{equation*}
        \begin{bmatrix}
            3 & 1 & -1 \\
            2 & 2 & -1 \\
            2 & 2 & 0
        \end{bmatrix}
        .
    \end{equation*}
    Then the characteristic polynomial for \(A\) is
    \begin{equation*}
        \begin{vmatrix}
            x-3 & -1 & 1 \\
            -2 & x-2 & 1 \\
            -2 & -2 & x
        \end{vmatrix}
        =x^3-5x^2+8x-4=\left(x-1\right)\left(x-2\right)^2.
    \end{equation*}
    Thus the characteristic values of \(A\) are \(1\) and \(2\).
    
    Suppose that \(T\) is the linear operator on \(R^3\) which is represented by \(A\) in the standard basis. Let us find the characteristic vectors of \(T\) associated with the characteristic values, \(1\) and \(2\). Now
    \begin{equation*}
        A-I=
        \begin{bmatrix}
            2 & 1 & -1 \\
            2 & 1 & -1 \\
            2 & 2 & -1
        \end{bmatrix}
        .
    \end{equation*}
    It is obvious at a glance that \(A-I\) has rank equal to \(2\) (and hence \(T-I\) has nullity equal to \(1\)). So the space of characteristic vectors associated with the characteristic value \(1\) is one-dimensional. The vector \(\alpha_1=\left(1,0,2\right)\) spans the null space of \(T-I\). Thus \(T\alpha=\alpha\) if and only if \(\alpha\) is a scalar multiple of \(\alpha_1\). Now consider
    \begin{equation*}
        A-2I=
        \begin{bmatrix}
            1 & 1 & -1 \\
            2 & 0 & -1 \\
            2 & 2 & -2
        \end{bmatrix}
        .
    \end{equation*}
    Evidently \(A-2I\) also has rank \(2\), so that the space of characteristic vectors associated with the characteristic value \(2\) has dimension \(1\). Evidently \(T\alpha=2\alpha\) if and only if \(\alpha\) is a scalar multiple of \(\alpha_2=\left(1,1,2\right)\).
\end{example}

\begin{definition}
    Let \(T\) be a linear operator on the finite-dimensional space \(V\). We say that \(T\) is \emph{diagonalizable} if there is a basis for \(V\) each vector of which is a characteristic vector of \(T\).
\end{definition}

The reason for the name should be apparent; for, if there is an ordered basis \(\symcal{B}=\set{\alpha_1,\ldots,\alpha_n}\) for \(V\) in which each \(\alpha_i\) is a characteristic vector of \(T\), then the matrix of \(T\) in the ordered basis \(\symcal{B}\) is diagonal. If \(T_{\alpha_i}=c_i\alpha_i\), then
\begin{equation*}
    \left[T\right]_{\symcal{B}}=
    \begin{bmatrix}
        c_1 & 0 & \cdots & 0 \\
        0 & c_2 & \cdots & 0 \\
        \vdots & \vdots && \vdots \\
        0 & 0 & \cdots & c_n
    \end{bmatrix}
    .
\end{equation*}
We certainly do not require that the scalars \(c_1,\ldots,c_n\) be distinct; indeed, they may all be the same scalar (when \(T\) is a scalar multiple of the identity operator).

One could also define \(T\) to be diagonalizable when the characteristic vectors of \(T\) span \(V\). This is only superficially different from our definition, since we can select a basis out of any spanning set of vectors.

For Examples~\ref{example:6.1} and \ref{example:6.2} we purposely chose linear operators \(T\) on \(R^n\) which are not diagonalizable. In Example~\ref{example:6.1}, we have a linear operator on \(R^2\) which is not diagonalizable, because it has no characteristic values. In Example~\ref{example:6.2}, the operator \(T\) has characteristic values; in fact, the characteristic polynomial for \(T\) factors completely over the real number field: \(f=\left(x-1\right)\left(x-2\right)^2\). Nevertheless \(T\) fails to be diagonalizable. There is only a one-dimensional space of characteristic vectors associated with each of the two characteristic values of \(T\). Hence, we cannot possibly form a basis for \(R^3\) which consists of characteristic vectors of \(T\).

Suppose that \(T\) is a diagonalizable linear operator. Let \(c_1\), \(\ldots\), \(c_k\) be the \emph{distinct} characteristic values of \(T\). Then there is an ordered basis \(\symcal{B}\) in which \(T\) is represented by a diagonal matrix which has for its diagonal entries the scalars \(c_i\), each repeated a certain number of times. If \(c_i\) is repeated \(d_i\) times, then (we may arrange that) the matrix has the block form
\begin{equation}
    \left[T\right]_{\symcal{B}}=
    \begin{bmatrix}
        c_1I_1 & 0 & \cdots & 0 \\
        0 & c_2I_2 & \cdots & 0 \\
        \vdots & \vdots && \vdots \\
        0 & 0 & \cdots & c_kI_k
    \end{bmatrix}
    \label{eq:6.3}
\end{equation}
where \(I_j\) is the \(d_j\times d_j\) identity matrix. From that matrix we see two things. First, the characteristic polynomial for \(T\) is the product of (possibly repeated) linear factors:
\begin{equation*}
    f=\left(x-c_1\right)^{d_1}\cdots\left(x-c_k\right)^{d_k}
\end{equation*}
If the scalar field \(F\) is algebraically closed, e.g., the field of complex numbers, every polynomial over \(F\) can be so factored (see Section~\ref{section:4.5}); however, if \(F\) is not algebraically closed, we are citing a special property of \(T\) when we say that its characteristic polynomial has such a factorization. The second thing we see from \eqref{eq:6.3} is that \(d_i\), the number of times which \(c_i\) is repeated as root of \(f\), is equal to the dimension of the space of characteristic vectors associated with the characteristic value \(c_i\). That is because the nullity of a diagonal matrix is equal to the number of zeros which it has on its main diagonal, and the matrix \(\left[T-c_iI\right]_{\symcal{B}}\) has \(d_i\) zeros on its main diagonal. This relation between the dimension of the characteristic space and the multiplicity of the characteristic value as a root of \(f\) does not seem exciting at first; however, it will provide us with a simpler way of determining whether a given operator is diagonalizable.

\begin{lemma}
    Suppose that \(T\alpha=c\alpha\). If \(f\) is any polynomial, then \(f\left(T\right)\alpha=f\left(c\right)\alpha\).
\end{lemma}

\begin{proof}
    Exercise.
\end{proof}

\begin{lemma}
    Let \(T\) be a linear operator on the finite-dimensional space \(V\). Let \(c_1\), \(\ldots\), \(c_k\) be the distinct characteristic values of \(T\) and let \(W_i\) be the space of characteristic vectors associated with the characteristic value \(c_i\). If \(W=W_1+\cdots+W_k\), then
    \begin{equation*}
        \dim W=\dim W_1+\cdots+\dim W_k.
    \end{equation*}
    In fact, if \(\symcal{B}_i\) is an ordered basis for \(W_i\), then \(\symcal{B}=\left(\symcal{B}_1,\ldots,\symcal{B}_k\right)\) is an ordered basis for \(W\).
\end{lemma}

\begin{proof}
    The space \(W=W_1+\cdots+W_k\) is the subspace spanned by all of the characteristic vectors of \(T\). Usually when one forms the sum \(W\) of subspaces \(W_i\), one expects that \(\dim W<\dim W_1+\cdots+\dim W_k\) because of linear relations which may exist between vectors in the various spaces. This lemma states that the characteristic spaces associated with different characteristic values are independent of one another.

    Suppose that (for each \(i\)) we have a vector \(\beta_i\) in \(W_i\), and assume that \(\beta_1+\cdots+\beta_k=0\). We shall show that \(\beta_i=0\) for each \(i\). Let \(f\) be any polynomial. Since \(T\beta_i=c_i\beta_i\), the preceding lemma tells us that
    \begin{align*}
        0=f\left(T\right)0&=f\left(T\right)\beta_1+\cdots+f\left(T\right)\beta_k\\
                          &=f\left(c_1\right)\beta_1+\cdots+f\left(c_k\right)\beta_k.
    \end{align*}
    Choose polynomials \(f_1\), \(\ldots\), \(f_k\) such that
    \begin{equation*}
        f_i\left(c_i\right)=\delta_{ij}=
        \begin{cases*}
            1, & \(i=j\) \\
            0, & \(i\ne j\).
        \end{cases*}
    \end{equation*}
    Then
    \begin{align*}
        0=f_i\left(T\right)0&=\sum_j\delta_{ij}\beta_j\\
                            &=\beta_i.
    \end{align*}
    Now, let \(\symcal{B}_i\) be an ordered basis for \(W_i\), and let \(\symcal{B}\) be the sequence \(\symcal{B}=\left(\symcal{B}_1,\ldots,\symcal{B}_k\right)\). Then \(\symcal{B}\) spans the subspace \(W=W_i+\cdots+W_k\). Also, \(\symcal{B}\) is a linearly independent sequence of vectors, for the following reason. Any linear relation between the vectors in \(\symcal{B}\) will have the form \(\beta_1+\cdots+\beta_k=0\), where \(\beta_i\) is some linear combination of the vectors in \(\symcal{B}_i\). From what we just did, we know that \(\beta_i=0\) for each \(i\). Since each \(\symcal{B}_i\) is linearly independent, we see that we have only the trivial linear relation between the vectors in \(\symcal{B}\).
\end{proof}

\begin{theorem}\label{theorem:6.2}
    Let \(T\) be a linear operator on a finite-dimensional space \(V\). Let \(c_1\), \(\ldots\), \(c_k\) be the distinct characteristic values of \(T\) and let \(W_i\) be the null space of \(\left(T-c_iI\right)\). The following are equivalent.
    \begin{enumerate}
        \item\label{itm:6.2.6} \(T\) is diagonalizable.
        \item\label{itm:6.2.7} The characteristic polynomial for \(T\) is
            \begin{equation*}
                f=\left(X-c_1\right)^{d_1}\cdots\left(X-c_k\right)^{d_k}
            \end{equation*}
            and \(\dim W_i=d_i\), \(i=1,\ldots,k\).
        \item\label{itm:6.2.8} \(\dim W_1+\cdots+\dim W_k=\dim V\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    We have observed that \ref{itm:6.2.6} implies \ref{itm:6.2.7}. If the characteristic polynomial \(f\) is the product of linear factors, as in \ref{itm:6.2.7}, then \(d_1+\cdots+d_k=\dim V\). For, the sum of the \(d_i\)'s is the degree of the characteristic polynomial, and that degree is \(\dim V\). Therefore \ref{itm:6.2.7} implies \ref{itm:6.2.8}. Suppose \ref{itm:6.2.8} holds. By the lemma, we must have \(V=W_1+\cdots+W_k\), i.e., the characteristic vectors of \(T\) span \(V\).
\end{proof}

The matrix analogue of Theorem~\ref{theorem:6.2} may be formulated as follows. Let \(A\) be an \(n\times n\) matrix with entries in a field \(F\), and let \(c_1\), \(\ldots\), \(c_k\) be the distinct characteristic values of \(A\) in \(F\). For each \(i\), let \(W_i\) be the space of column matrices \(X\) (with entries in \(F\)) such that
\begin{equation*}
   \left(A-c_iI\right)X=0,
\end{equation*}
and let \(\symcal{B}_i\) be an ordered basis for \(W_i\). The bases \(\symcal{B}_1\), \(\ldots\), \(\symcal{B}_k\) collectively string together to form the sequence of columns of a matrix \(P\):
\begin{equation*}
    P=\left[P_1,P_2,\ldots\right]=\left(\symcal{B}_1,\ldots,\symcal{B}_k\right).
\end{equation*}
The matrix \(A\) is similar over \(F\) to a diagonal matrix if and only if \(P\) is a square matrix. When \(P\) is square, \(P\) is invertible and \(P^{-1}AP\) is diagonal.

\begin{example}
    Let \(T\) be the linear operator on \(R^3\) which is represented in the standard ordered basis by the matrix
    \begin{equation*}
        A=
        \begin{bmatrix}
            5 & -6 & -6 \\
            -1 & 4 & 2 \\
            3 & -6 & -4
        \end{bmatrix}
        .
    \end{equation*}
    Let us indicate how one might compute the characteristic polynomial, using various row and column operations:
    \begin{align*}
        \begin{vmatrix}
            x-5 & 6 & 6 \\
            1 & x-4 & -2 \\
            -3 & 6 & x+4
        \end{vmatrix}
        &=
        \begin{vmatrix}
            x-5 & 0 & 6 \\
            1 & x-2 & -2 \\
            -3 & 2-x & x+4
        \end{vmatrix}
        \\
        &=\left(x-2\right)
        \begin{vmatrix}
            x-5 & 0 & 6 \\
            1 & 1 & -2 \\
            -3 & -1 & x+4
        \end{vmatrix}
        \\
        &=\left(x-2\right)
        \begin{vmatrix}
            x-5 & 6 \\
            -2 & x+2
        \end{vmatrix}
        \\
        &=\left(x-2\right)\left(x^2-3x+2\right)\\
        &=\left(x-2\right)^2\left(x-1\right).
    \end{align*}
    What are the dimensions of the spaces of characteristic vectors associated with the two characteristic values? We have
    \begin{align*}
        A-I&=
        \begin{bmatrix}
            4 & -6 & -6 \\
            -1 & 3 & 2 \\
            3 & -6 & -5
        \end{bmatrix}
        \\
        A-2I&=
        \begin{bmatrix}
            3 & -6 & -6 \\
            -1 & 2 & 2 \\
            3 & -6 & -6
        \end{bmatrix}
        .
    \end{align*}
    We know that \(A-I\) is singular and obviously \(\rank\left(A-I\right)\geqslant2\). Therefore, \(\rank\left(A-I\right)=2\). It is evident that \(\rank\left(A-2I\right)=1\).

    Let \(W_1\), \(W_2\) be the spaces of characteristic vectors associated with the characteristic values \(1\), \(2\). We know that \(\dim W_1=1\) and \(\dim W_2=2\). By Theorem~\ref{theorem:6.2}, \(T\) is diagonalizable. It is easy to exhibit a basis for \(R^3\) in which \(T\) is represented by a diagonal matrix. The null space of \(\left(T-I\right)\) is spanned by the vector \(\alpha_1=\left(3,-1,3\right)\) and so \(\alpha_1\) is a basis for \(W_1\). The null space of \(T-2I\) (i.e., the space \(W_2\)) consists of the vectors \(\left(x_1,x_2,x_3\right)\) with \(x_1=2x_2+2x_3\). Thus, one example of a basis for \(W_2\) is
    \begin{align*}
        \alpha_2&=\left(2,1,0\right)\\
        \alpha_3&=\left(2,0,1\right).
    \end{align*}
    If \(\symcal{B}=\set{\alpha_1,\alpha_2,\alpha_3}\), then \(\left[T\right]_{\symcal{B}}\) is the diagonal matrix
    \begin{equation*}
        D=
        \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 2 & 0 \\
            0 & 0 & 2
        \end{bmatrix}
        .
    \end{equation*}
    The fact that \(T\) is diagonalisable means that the original matrix \(A\) is similar (over \(R\)) to the diagonal matrix \(D\). The matrix \(P\) which enables us to change coordinates from the basis \(\symcal{B}\) to the standard basis is (of course) the matrix which has the transposes of \(\alpha_1\), \(\alpha_2\), \(\alpha_3\) as its column vectors:
    \begin{equation*}
        P=
        \begin{bmatrix}
            3 & 2 & 2 \\
            -1 & 1 & 0 \\
            3 & 0 & 1
        \end{bmatrix}
        .
    \end{equation*}
    Furthermore, \(AP=PD\), so that
    \begin{equation*}
        P^{-1}AP=D.
    \end{equation*}
\end{example}

\subsection*{Exercises}

\begin{enumerate}
    \item In each of the following cases, let \(T\) be the linear operator on \(R^2\) which is represented by the matrix \(A\) in the standard ordered basis for \(R^2\), and let \(U\) be the linear operator on \(C^2\) represented by \(A\) in the standard ordered basis. Find the characteristic polynomial for \(T\) and that for \(U\), find the characteristic values of each operator, and for each such characteristic value \(c\) find a basis for the corresponding space of characteristic vectors.
        \begin{equation*}
            A=
            \begin{bmatrix}
                1 & 0 \\
                0 & 0
            \end{bmatrix}
            ,\qquad A=
            \begin{bmatrix}
                2 & 3 \\
                -1 & 1
            \end{bmatrix}
            ,\qquad A=
            \begin{bmatrix}
                1 & 1 \\
                1 & 1
            \end{bmatrix}
            .
        \end{equation*}
    \item Let \(V\) be an \(n\)-dimensional vector space over \(F\). What is the characteristic polynomial of the identity operator on \(V\)? What is the characteristic polynomial for the zero operator?
    \item Let \(A\) be an \(n\times n\) triangular matrix over the field \(F\). Prove that the characteristic values of \(A\) are the diagonal entries of \(A\), i.e., the scalars \(A_{ii}\).
    \item Let \(T\) be the linear operator on \(R^3\) which is represented in the standard ordered basis by the matrix
        \begin{equation*}
            \begin{bmatrix}
                -9 & 4 & 4 \\
                -8 & 3 & 4 \\
                -16 & 8 & 7
            \end{bmatrix}
            .
        \end{equation*}
        Prove that \(T\) is diagonalizable by exhibiting a basis for \(R^3\), each vector of which is a characteristic vector of \(T\).
    \item Let
        \begin{equation*}
            A=
            \begin{bmatrix}
                6 & -3 & -2 \\
                4 & -1 & -2 \\
                10 & -5 & -3
            \end{bmatrix}
            .
        \end{equation*}
        Is \(A\) similar over the field \(R\) to a diagonal matrix? Is \(A\) similar over the field \(C\) to a diagonal matrix?
    \item Let \(T\) be the linear operator on \(R^4\) which is represented in the standard ordered basis by the matrix
        \begin{equation*}
            \begin{bmatrix}
                0 & 0 & 0 & 0 \\
                a & 0 & 0 & 0 \\
                0 & b & 0 & 0 \\
                0 & 0 & c & 0
            \end{bmatrix}
            .
        \end{equation*}
        Under what conditions on \(a\), \(b\), and \(c\) is \(T\) diagonalizable?
    \item Let \(T\) be a linear operator on the \(n\)-dimensional vector space \(V\), and suppose that \(T\) has \(n\) \emph{distinct} characteristic values. Prove that \(T\) is diagonalizable.
    \item\label{exercise:6.2.8} Let \(A\) and \(B\) be \(n\times n\) matrices over the field \(F\). Prove that if \(\left(I-AB\right)\) is invertible, then \(I-BA\) is invertible and
        \begin{equation*}
            \left(I-BA\right)^{-1}=I+B\left(I-AB\right)^{-1}A.
        \end{equation*}
    \item Use the result of Exercise~\ref{exercise:6.2.8} to prove that, if \(A\) and \(B\) are \(n\times n\) matrices over the field \(F\), then \(AB\) and \(BA\) have precisely the same characteristic values in \(F\).
    \item Suppose that \(A\) is a \(2\times2\) matrix with real entries which is symmetric (\(A^\transpose=A\)). Prove that \(A\) is similar over \(R\) to a diagonal matrix.
    \item\label{exercise:6.2.11} Let \(N\) be a \(2\times2\) complex matrix such that \(N^2=0\). Prove that either \(N=0\) or \(N\) is similar over \(C\) to
        \begin{equation*}
            \begin{bmatrix}
                0 & 0 \\
                1 & 0
            \end{bmatrix}
            .
        \end{equation*}
    \item Use the result of Exercise~\ref{exercise:6.2.11} to prove the following: If \(A\) is a \(2\times2\) matrix with complex entries, then \(A\) is similar over \(C\) to a matrix of one of the two types
        \begin{equation*}
            \begin{bmatrix}
                a & 0 \\
                0 & b
            \end{bmatrix}
            \qquad
            \begin{bmatrix}
                a & 0 \\
                1 & a
            \end{bmatrix}
            .
        \end{equation*}
    \item Let \(V\) be the vector space of all functions from \(R\) into \(R\) which are continuous, i.e., the space of continuous real-valued functions on the real line. Let \(T\) be the linear operator on \(V\) defined by
        \begin{equation*}
            \left(Tf\right)\left(x\right)=\int_0^xf\left(t\right)\odif{t}.
        \end{equation*}
        Prove that \(T\) has no characteristic values.
    \item Let \(A\) be an \(n\times n\) diagonal matrix with characteristic polynomial
        \begin{equation*}
            \left(x-c_1\right)^{d_1}\cdots\left(x-c_k\right)^{d_k},
        \end{equation*}
        where \(c_1\), \(\ldots\), \(c_k\) are distinct. Let \(V\) be the space of \(n\times n\) matrices \(B\) such that \(AB=BA\). Prove that the dimension of \(V\) is \(d_1^2+\cdots+d_k^2\).
    \item Let \(V\) be the space of \(n\times n\) matrices over \(F\). Let \(A\) be a fixed \(n\times n\) matrix over \(F\). Let \(T\) be the linear operator `left multiplication by \(A\)' on \(V\). Is it true that \(A\) and \(T\) have the same characteristic values?
\end{enumerate}

