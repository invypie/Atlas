\section{Introduction}

We have mentioned earlier that our principal aim is to study linear transformations on finite-dimensional vector spaces. By this time, we have seen many specific examples of linear transformations, and we have proved a few theorems about the general linear transformation. In the finite-dimensional case we have utilized ordered bases to represent such transformations by matrices, and this representation adds to our insight into their behavior. We have explored the vector space \(L\left(V,W\right)\), consisting of the linear transformations from one space into another, and we have explored the linear algebra \(L\left(V,V\right)\), consisting of the linear transformations of a space into itself.

In the next two chapters, we shall be preoccupied with linear operators. Our program is to select a single linear operator \(T\) on a finite-dimensional vector space \(V\) and to `take it apart to see what makes it tick.' At this early stage, it is easiest to express our goal in matrix language: Given the linear operator \(T\), find an ordered basis for \(V\) in which the matrix of \(T\) assumes an especially simple form.

Here is an illustration of what we have in mind. Perhaps the simplest matrices to work with, beyond the scalar multiples of the identity, are the diagonal matrices:
\begin{equation}
    D=
    \begin{bmatrix}
        c_1 & 0 & 0 & \cdots & 0 \\
        0 & c_2 & 0 & \cdots & 0 \\
        0 & 0 & c_3 & \cdots & 0 \\
        \vdots & \vdots & \vdots && \vdots \\
        0 & 0 & 0 & \cdots & c_n
    \end{bmatrix}
    .\label{eq:6.1}
\end{equation}
Let \(T\) be a linear operator on an \(n\)-dimensional space \(V\). If we could find an ordered basis \(\symcal{B}=\set{\alpha_1,\ldots,\alpha_n}\) for \(V\) in which \(T\) were represented by a diagonal matrix \(D\) \eqref{eq:6.1}, we would gain considerable information about \(T\). For instance, simple numbers associated with \(T\), such as the rank of \(T\) or the determinant of \(T\), could be determined with little more than a glance at the matrix \(D\). We could describe explicitly the range and the null space of \(T\). Since \(\left[T\right]_{\symcal{B}}=D\) if and only if
\begin{equation}
    T_{\alpha_k}=c_k\alpha_k,\qquad k=1,\ldots,n,\label{eq:6.2}
\end{equation}
the range would be the subspace spanned by those \(\alpha_k\)'s for which \(c_k\ne0\) and the null space would be spanned by the remaining \(\alpha_k\)'s. Indeed, it seems fair to say that, if we knew a basis \(\symcal{B}\) and a diagonal matrix \(D\) such that \(\left[T\right]_{\symcal{B}}=D\), we could answer readily any question about \(T\) which might arise.

Can each linear operator \(T\) be represented by a diagonal matrix in some ordered basis? If not, for which operators \(T\) does such a basis exist? How can we find such a basis if there is one? If no such basis exists, what is the simplest type of matrix by which we can represent \(T\)? These are some of the questions which we shall attack in this (and the next) chapter. The form of our questions will become more sophisticated as we learn what some of the difficulties are.
